{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd # used to load the data\n",
    "import numpy as np # optimized numerical library\n",
    "\n",
    "from sklearn import preprocessing, metrics, utils, decomposition, model_selection, linear_model, discriminant_analysis, svm, tree, ensemble # library providing several ML algorithms and related utility\n",
    "from imblearn import over_sampling # provides several resampling techniques to cope with unbalanced datasets (https://github.com/scikit-learn-contrib/imbalanced-learn) compatible with sklearn\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt # used for plotting\n",
    "\n",
    "# Start by defining three helper functions:\n",
    "# - one to plot the sample distribution  acorss the class labels (to see how un-/balanced the dataset is)\n",
    "# - one to compute and plot the confusion matrix\n",
    "# - one to plot data in 2D with different colors per class label\n",
    "\n",
    "def plot_pie(y, labels, title=\"\"):\n",
    "    target_stats = Counter(y)\n",
    "    sizes = list(target_stats.values())\n",
    "    explode = tuple([0.1] * len(target_stats))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title + \" (size: %d)\" % len(y))\n",
    "    ax.pie(sizes, explode=explode, labels=target_stats.keys(), shadow=True, autopct='%1.1f%%')\n",
    "    ax.axis('equal')\n",
    "\n",
    "\n",
    "def compute_and_plot_cm(ytest, ypred, labels, title=\"\"):\n",
    "    global nfigure\n",
    "    # Compute confusion matrix\n",
    "    cm = metrics.confusion_matrix(ytest, ypred)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(ytest, ypred, normalize=True)\n",
    "\n",
    "    # Normalize the matrix\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "\n",
    "    nfigure = nfigure + 1\n",
    "    plt.figure(nfigure) # new numbered figure\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues) # plot the confusionmatrix using blue shaded colors\n",
    "    plt.title(\"Confusion Matrix Normalized (%s) Accuracy: %.1f%%\" % (title, accuracy*100)) # add title\n",
    "    plt.colorbar() # plot the color bar as legend\n",
    "\n",
    "    # Plot the x and y ticks using the class label names\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "\n",
    "\n",
    "def plot_2d(xpred, ypred, labels, title=\"\"):\n",
    "    global nfigure\n",
    "    # define the colors to use for each class label\n",
    "    colors = ['red', 'blue', 'green', 'yellow', 'black']\n",
    "    len_colors = len(colors)\n",
    "    if len_colors < len(labels):\n",
    "        print(\"WARNING: we have less colors than classes: some classes will reuse the same color\")\n",
    "\n",
    "    nfigure = nfigure + 1\n",
    "    plt.figure(nfigure) # new numbered figure\n",
    "    plt.title(\"Feature Space (%s)\" % title) # add title\n",
    "\n",
    "\n",
    "    # plot each class label with a separate color \n",
    "    for c in range(len(labels)):\n",
    "        cur_class = (ypred == c) # get all points belonging to class c\n",
    "        plt.plot(xpred[cur_class, 0], xpred[cur_class, 1], 'o', color=colors[c % len_colors]) # plot class c\n",
    "\n",
    "\n",
    "nfigure = 0 #used to number the figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading and visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################ Load data ####################\n",
    "# Get the dataset loaded and define class labels \n",
    "data = pd.read_csv('data/diabetes.csv', header=0)\n",
    "data_class_labels = [\"no diabetes\", \"diabetes\"]\n",
    "\n",
    "# All data columns except last are input features (X), last column is output label (y)\n",
    "n_features = len(data.columns) - 1\n",
    "\n",
    "X = data.iloc[:,0:n_features]\n",
    "y = data.iloc[:,n_features]\n",
    "\n",
    "plot_pie(y, data_class_labels, \"Original\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/diabetes.csv', header=0)\n",
    "data_class_labels = [\"no diabetes\", \"diabetes\"]\n",
    "n_features = len(data.columns) - 1\n",
    "\n",
    "X = data.iloc[:,0:n_features]\n",
    "y = data.iloc[:,n_features]\n",
    "n_features\n",
    "plot_pie(y, data_class_labels, \"Original\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing the data set\n",
    "## Split the data into traning and testing: model_selection.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ Split data ####################\n",
    "# Split data in training and testing\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the size and value ranges of X_train\n",
    "Do you see any problem? \n",
    "What function  to use to find the max and min values for each feature? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the size of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the max values of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the min values of all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the  data range: preprocessing.StandardScaler().fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ Scale data ####################\n",
    "# Train a scaler to standardize the features (zero mean and unit variance)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# ... and scale the features\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the two principle components: decomposition.PCA(n_components=n).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ PCA ####################\n",
    "# Train a PCA with 2 dimensions\n",
    "pca = decomposition.PCA(n_components=2).fit(X_train_scaled)\n",
    "\n",
    "# ... and apply it to the features\n",
    "X_train_scaled_pca = pca.transform(X_train_scaled)\n",
    "X_test_scaled_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression:  linear_model.LogisticRegression().fit()\n",
    "### Original feature: fit, predict, accuracy, confusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Logit ##################\n",
    "# Train a Logit model on the original features\n",
    "lr = linear_model.LogisticRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "y_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Acuracy of LR : %.1f%%\" % (metrics.accuracy_score(y_test,y_lr)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "compute_and_plot_cm(y_test, y_lr, data_class_labels, title=\"LR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two principle components:  fit, predict, accuracy, confusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logit model on pca extracted features\n",
    "lr_pca = linear_model.LogisticRegression().fit(X_train_scaled_pca, y_train)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "y_lr_pca = lr_pca.predict(X_test_scaled_pca)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy of LR + PCA: %.1f%%\" % (metrics.accuracy_score(y_test,y_lr_pca)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "compute_and_plot_cm(y_test, y_lr_pca, data_class_labels, title=\"LR + PCA\")\n",
    "plt.show()\n",
    "\n",
    "# visualize the predictions based on 2 PCA components\n",
    "plot_2d(X_test_scaled_pca, y_lr_pca, data_class_labels, title=\"LR + PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LDA: discriminant_analysis.LinearDiscriminantAnalysis().fit()\n",
    "### Original feature: fit, predict, accuracy, confusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ LDA ##################\n",
    "# Train an LDA model on original features\n",
    "#lda = discriminant_analysis.LinearDiscriminantAnalysis().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "#y_lda = \n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of LDA: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two principle components: fit, predict, accuracy, confusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train an LDA model on pca extracted features\n",
    "# lda_pca = discriminant_analysis.LinearDiscriminantAnalysis().fit(,)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "# y_lda_pca =\n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of LDA+PCA: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")\n",
    "\n",
    "# visualize the predictions based on 2 PCA components\n",
    "#plot_2d(,, , title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. QDA: discriminant_analysis.QuadraticDiscriminantAnalysis().fit()\n",
    "### Original feature: fit, predict, accuracy, confusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ QDA ##################\n",
    "# Train a QDA model on original features\n",
    "qda = discriminant_analysis.QuadraticDiscriminantAnalysis().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "#y_qda =\n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of QDA: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two principle components: fit, predict, accuracy, confusion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a QDA model on pca extracted features\n",
    "#qda_pca = discriminant_analysis.QuadraticDiscriminantAnalysis().fit(, )\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "#y_qda_pca=\n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of QDA+PCA: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")\n",
    "\n",
    "# visualize the predictions based on 2 PCA components\n",
    "#plot_2d(,, , title=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ELDA\n",
    "### Expanded bases of original feature: preprocessing.PolynomialFeatures(degree=k).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ Polynomial expanded features ##################\n",
    "# Train a polynomial expansion on original features\n",
    "poly2 = preprocessing.PolynomialFeatures(degree=2).fit(X_train_scaled_pca)\n",
    "\n",
    "# ... and apply it to the features\n",
    "X_train_scaled_poly2 = poly2.transform(X_train_scaled_pca)\n",
    "X_test_scaled_poly2 = poly2.transform(X_test_scaled_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting LDA on the expanded features: discriminant_analysis.linearDiscriminantAnalysis().fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################  LDA on expanded ##################\n",
    "# Train an LDA model on the original expanded features\n",
    "#lda_poly2 = discriminant_analysis.LinearDiscriminantAnalysis().fit(, )\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "#y_lda_poly2=\n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of ELDA: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Support Vector Machine: svm.SVC().fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ SVM ##################\n",
    "# Train a SVM model on the original features\n",
    "#sv = svm.SVC().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "#y_sv = sv.\n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of SVM: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework: apply SVM on the 2 principle components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Decision Tree: tree.DecisionTreeClassifier(max_depth=n).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################ DecisionTree ##################\n",
    "# Train a DT model on the original features\n",
    "#dt = tree.DecisionTreeClassifier(max_depth=5).fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "#y_dt = dt. \n",
    "\n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of DT: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework: apply Decision Tree on the 2 principle components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Random Forest:  ensemble.RandomForestClassifier.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ RandomForest ##################\n",
    "# Train a RF model on the original features\n",
    "#rf = ensemble.RandomForestClassifier().fit(X_train_scaled, y_train)\n",
    "\n",
    "# Compute the predicted labels on test data\n",
    "#y_rf = rf.\n",
    "\n",
    "\n",
    "# Print the accuracy\n",
    "#print(\"Accuracy of Random Forest: %.1f%%\" % (metrics.accuracy_score(,)*100))\n",
    "\n",
    "# Compute and print and confusion matrix\n",
    "#compute_and_plot_cm(, , , title=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework: apply Random Forest on the 2 principle components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
